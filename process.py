import os
import sys
import aiohttp
import asyncio
import concurrent.futures
import nest_asyncio
import re
import random
import requests
import time
import threading
from typing import Any, List, Optional, Dict, Tuple
from datetime import datetime

# Importações de bibliotecas externas
import openai
from docx import Document
from docx.shared import Pt, Inches, RGBColor
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT, WD_ALIGN_PARAGRAPH
from docx.oxml import parse_xml
from docx.oxml.ns import nsdecls
from docx.enum.style import WD_STYLE_TYPE

# Configurar a API Key
openai.api_key = os.getenv("OPENAI_API_KEY")

if not openai.api_key:
    raise ValueError("A chave da OpenAI não foi configurada corretamente no Railway!")

def gerar_indice(discipline, theme, text_type, total_pages):
    """
    Gera um índice para um documento acadêmico baseado nos parâmetros fornecidos.
    """
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Você é um assistente útil."},
                {"role": "user", "content": f"Você é um especialista acadêmico. Elabore um índice com que respeite a seguinte regra de número de itens: dois terços de {total_pages}. Esse número deve ser o TOTAL, dividido entre entre tópicos e subtópicos, de uma '{text_type}' sobre o tema '{theme}' no contexto do curso de '{discipline}'. Use o formato 1. para numerar tópicos principais (2., 3., 4., assim por diante) e 1.1 para numerar subtópicos (1.2, 1.3, 1.4, 2.1, 2.2, 2.3 assim por diante). Certifique-se de que o índice reflita uma progressão lógica e coerente das ideias e evite redundâncias. Não acrescente mais nada (asteriscos, comentários, etc) ao índice além do pedido"}
            ]
        )

        resultado = response['choices'][0]['message']['content']
        return [{"title": linha.strip()} for linha in resultado.strip().split('\n') if linha.strip()]
    
    except Exception as e:
        return {"erro": f"Erro ao chamar OpenAI: {str(e)}"}

def executar_processo_completo(discipline, theme, text_type, total_pages):
    """
    Executa o processo completo: gera o índice e retorna os resultados.
    """
    indice = gerar_indice(discipline, theme, text_type, total_pages)
    return indice



# -*- coding: utf-8 -*-
"""Copy of Gerador de textos simplificado.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NjLT77WZfFxUpPHjAFmtwlizn8BKxkWK
"""

class CrossrefClient:
    def __init__(self):
        self.base_url = "https://api.crossref.org/works"
        self.headers = {
            'User-Agent': 'PythonResearchScript/1.0 (mailto:your@email.com)'
        }

    def get_work_details(self, doi: str) -> Dict:
        try:
            url = f"{self.base_url}/{doi}"
            response = requests.get(url, headers=self.headers)
            if response.status_code == 200:
                return response.json().get('message', {})
            return {}
        except Exception as e:
            print(f"Erro ao obter detalhes do DOI {doi}: {e}")
            return {}

    def search_works(self, query: str, limit: int) -> List[Dict]:
        SEARCH_LIMIT = 50
        query = query.replace('"', '').lower()
        search_terms = query.split()

        params_pt = {
            'query': query,
            'rows': SEARCH_LIMIT,
            'filter': 'type:journal-article,language:pt',
            'sort': 'relevance'
        }

        scored_works = []
        try:
            # Primeira busca em português
            response = requests.get(self.base_url, params=params_pt, headers=self.headers)
            if response.status_code == 200:
                data = response.json()
                items = data.get('message', {}).get('items', [])
                for item in items:
                    doi = item.get('DOI')
                    if doi:
                        details = self.get_work_details(doi)
                        if details:
                            score = 0
                            title = details.get('title', [''])[0].lower() if details.get('title') else ''
                            abstract = details.get('abstract', '').lower() if details.get('abstract') else ''
                            keywords = [k.lower() for k in details.get('keyword', [])]

                            language = details.get('language', '').lower()
                            if language == 'pt' or language == 'por':
                                score += 15

                            if all(term in title for term in search_terms):
                                score += 100
                            else:
                                score += sum(10 for term in search_terms if term in title)

                            score += sum(5 for term in search_terms if term in abstract)
                            score += sum(3 for term in search_terms if any(term in k for k in keywords))

                            if score > 0:
                                authors = details.get('author', [])
                                author_list = [f"{a.get('family', '')}, {a.get('given', '')}" for a in authors if a]
                                work_data = {
                                    'doi': details.get('DOI', ''),
                                    'title': title,
                                    'authors': author_list,
                                    'publisher': details.get('publisher', ''),
                                    'container_title': details.get('container-title', [''])[0] if details.get('container-title') else '',
                                    'type': details.get('type', ''),
                                    'published_print': details.get('published-print'),
                                    'published_online': details.get('published-online'),
                                    'abstract': details.get('abstract', ''),
                                    'keywords': details.get('keyword', []),
                                    'license': [lic.get('URL', '') for lic in details.get('license', [])],
                                    'language': language,
                                    '_score': score
                                }
                                scored_works.append((score, work_data))
                        time.sleep(0.5)

            # Busca em todas as línguas
            params_all = {
                'query': query,
                'rows': SEARCH_LIMIT,
                'filter': 'type:journal-article',
                'sort': 'relevance'
            }

            response = requests.get(self.base_url, params=params_all, headers=self.headers)
            if response.status_code == 200:
                data = response.json()
                items = data.get('message', {}).get('items', [])
                for item in items:
                    doi = item.get('DOI')
                    if doi and not any(work[1]['doi'] == doi for work in scored_works):
                        details = self.get_work_details(doi)
                        if details:
                            score = 0
                            title = details.get('title', [''])[0].lower() if details.get('title') else ''
                            abstract = details.get('abstract', '').lower() if details.get('abstract') else ''
                            keywords = [k.lower() for k in details.get('keyword', [])]
                            language = details.get('language', '').lower()

                            if all(term in title for term in search_terms):
                                score += 100
                            else:
                                score += sum(10 for term in search_terms if term in title)

                            score += sum(5 for term in search_terms if term in abstract)
                            score += sum(3 for term in search_terms if any(term in k for k in keywords))

                            if score > 0:
                                authors = details.get('author', [])
                                author_list = [f"{a.get('family', '')}, {a.get('given', '')}" for a in authors if a]
                                work_data = {
                                    'doi': details.get('DOI', ''),
                                    'title': title,
                                    'authors': author_list,
                                    'publisher': details.get('publisher', ''),
                                    'container_title': details.get('container-title', [''])[0] if details.get('container-title') else '',
                                    'type': details.get('type', ''),
                                    'published_print': details.get('published-print'),
                                    'published_online': details.get('published-online'),
                                    'abstract': details.get('abstract', ''),
                                    'keywords': details.get('keyword', []),
                                    'license': [lic.get('URL', '') for lic in details.get('license', [])],
                                    'language': language,
                                    '_score': score
                                }
                                scored_works.append((score, work_data))
                        time.sleep(0.5)

            if not scored_works:
                return []

            scored_works.sort(reverse=True, key=lambda x: x[0])
            return [work for score, work in scored_works[:limit]]
        except Exception as e:
            print(f"Erro durante a busca: {e}")
            return []

def get_references_from_scholar(theme: str, refs_num: int) -> Dict[str, any]:
    result = {
        'metadata': {
            'theme': theme,
            'requested_refs': refs_num,
            'timestamp': datetime.now().isoformat(),
            'query_successful': False,
            'total_found': 0
        },
        'references': []
    }

    client = CrossrefClient()
    references_data = client.search_works(theme, refs_num)

    if not references_data:
        print("Nenhuma referência encontrada.")
        return result

    result['metadata']['query_successful'] = True
    result['metadata']['total_found'] = len(references_data)

    for i, ref in enumerate(references_data, 1):
        reference_data = {
            'index': i,
            'title': ref['title'],
            'authors': ref['authors'],
            'publisher': ref['publisher'],
            'container_title': ref['container_title'],
            'type': ref['type'],
            'doi': ref['doi'],
            'abstract': ref['abstract'],
            'keywords': ref['keywords'],
            'license': ref['license'],
            'score': ref.get('_score', 0),
            'language': ref.get('language', ''),
            'published_print': ref['published_print'],
            'published_online': ref['published_online']
        }
        result['references'].append(reference_data)

    if result['references']:
        for ref in result['references']:
            print(f"Referência {ref['index']}:")
            print(f"Título: {ref['title']}")
            print(f"Autores: {', '.join(ref['authors']) if ref['authors'] else '[s.a.]'}")
            print(f"Publicação: {ref['container_title']}")
            print(f"Editora: {ref['publisher']}")
            print(f"DOI: {ref['doi']}\n")

    return result

# Execução de teste
resultado_referencias = get_references_from_scholar(theme, refs_num)

nest_asyncio.apply()
openai.api_key = os.getenv('OPENAI_API_KEY')

async def generate_intext_citation(session, reference: Dict, format_type: str) -> str:
    authors = ', '.join(reference['authors']) if reference['authors'] else '[s.a.]'
    year = ''
    if reference.get('published_print'):
        year = reference['published_print'].get('date-parts', [['']])[0][0]
    elif reference.get('published_online'):
        year = reference['published_online'].get('date-parts', [['']])[0][0]

    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {openai.api_key}",
        "Content-Type": "application/json"
    }

    data = {
        "model": "gpt-4o",
        "messages": [
            {"role": "system", "content": f"Você é um especialista em citações bibliográficas {format_type}."},
            {"role": "user", "content": f"""
            Gere APENAS a citação intra-texto no formato {format_type} para:
            Título: {reference['title']}
            Autores: {authors}
            Ano: {year}

            Responda APENAS com a citação, sem explicações.
            """}
        ]
    }

    async with session.post(url, json=data, headers=headers) as response:
        if response.status == 200:
            result = await response.json()
            return result['choices'][0]['message']['content'].strip()
        return None

async def generate_full_reference(session, reference: Dict, format_type: str) -> str:
    authors = ', '.join(reference['authors']) if reference['authors'] else '[s.a.]'
    year = ''
    if reference.get('published_print'):
        year = reference['published_print'].get('date-parts', [['']])[0][0]
    elif reference.get('published_online'):
        year = reference['published_online'].get('date-parts', [['']])[0][0]

    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {openai.api_key}",
        "Content-Type": "application/json"
    }

    data = {
        "model": "gpt-4o",
        "messages": [
            {"role": "system", "content": f"Você é um especialista em referências bibliográficas {format_type}."},
            {"role": "user", "content": f"""
            Formate no padrão {format_type}:
            Título: {reference['title']}
            Autores: {authors}
            Ano: {year}
            Publicação: {reference['container_title']}
            Editora: {reference['publisher']}
            DOI: {reference['doi']}

            Responda APENAS com a referência formatada.
            """}
        ]
    }

    async with session.post(url, json=data, headers=headers) as response:
        if response.status == 200:
            result = await response.json()
            return result['choices'][0]['message']['content'].strip()
        return None

async def process_all_references(references: List[Dict], format_type: str) -> Tuple[Dict[str, str], Dict[str, str]]:
    async with aiohttp.ClientSession() as session:
        intext_tasks = [generate_intext_citation(session, ref, format_type) for ref in references]
        intext_results = await asyncio.gather(*intext_tasks)

        intext_citations = {}
        for i, citation in enumerate(intext_results, 1):
            if citation:
                print(citation)
                intext_citations[f"ref_{i}"] = citation

        fullref_tasks = [generate_full_reference(session, ref, format_type) for ref in references]
        fullref_results = await asyncio.gather(*fullref_tasks)

        full_references = {}
        for i, ref in enumerate(fullref_results, 1):
            if ref:
                print(f"\n{ref}")
                full_references[f"ref_{i}"] = ref

    return intext_citations, full_references

loop = asyncio.get_event_loop()
intext_dict, fullref_dict = loop.run_until_complete(
    process_all_references(
        resultado_referencias['references'],
        reference_format
    )
)

referencias_processadas = {
    'intext': intext_dict,
    'full': fullref_dict,
    'metadata': {
        'format': reference_format,
        'count': len(intext_dict)
    }
}

nest_asyncio.apply()

global resultados_completos

class ProgressBar:
    def __init__(self, title, total_items):
        self.title = title[:35].ljust(35)
        self.width = 40
        self.is_running = True
        self.expected_time = (30 / 40) * total_items
        self.start_time = time.time()
        self.symbols = ["⠋", "⠙", "⠹", "⠸", "⠼", "⠴", "⠦", "⠧", "⠇", "⠏"]
        self.current_symbol = 0

    def _clear_line(self):
        sys.stdout.write('\r')
        sys.stdout.write(' ' * (self.width + 50))
        sys.stdout.write('\r')
        sys.stdout.flush()

    def update(self):
        while self.is_running:
            elapsed = time.time() - self.start_time
            progress = min(elapsed / self.expected_time, 0.95)
            filled = int(self.width * progress)
            bar = "█" * filled + "░" * (self.width - filled)
            symbol = self.symbols[self.current_symbol]
            self.current_symbol = (self.current_symbol + 1) % len(self.symbols)
            sys.stdout.write(f"\r{symbol} {self.title} [{bar}] {int(progress * 100)}%")
            sys.stdout.flush()
            time.sleep(0.1)

        bar = "█" * self.width
        sys.stdout.write(f"\r✓ {self.title} [{bar}] 100%\n")
        sys.stdout.flush()

    def start(self):
        self.thread = threading.Thread(target=self.update)
        self.thread.daemon = True
        self.thread.start()

    def complete(self):
        self.is_running = False
        if hasattr(self, 'thread'):
            self.thread.join()

openai.api_key = os.getenv('OPENAI_API_KEY')

async def obter_paragrafo(session, titulo, total_items):
    progress = ProgressBar(titulo, total_items)
    progress.start()

    url = "https://api.openai.com/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {openai.api_key}",
        "Content-Type": "application/json"
    }

    data = {
        "model": "gpt-4o",
        "messages": [
            {"role": "system", "content": "Você é um assistente útil."},
            {"role": "user", "content": f"Escreva dez (10) parágrafos densos (e evite numerá-los), em estilo acadêmico, longos e autoritativos para um subcapítulo de título '{titulo}', de um(a) {text_type} com o tema '{theme}' escrevendo um parágrafo para cada instrução aspecto do assunto. Foque em detalhes e especificidades desse subcapítulo {titulo}, sem reintroduzir o tópico principal {theme} e nem concluir a ideia. É PROIBIDO concluir o texto com expressões como 'por fim', 'finalmente', 'por último'. Esse é um meio de texto, então não devemos concluir isso de nenhuma maneira. Não adicione conclusões ou transições finais. Escreva o texto sem usar palavras ou frases de conclusão como 'por fim', 'finalmente', 'em conclusão', 'para concluir'. Mantenha o texto aberto para a próxima seção, sem concluir o ponto."}
        ]
    }

    try:
        async with session.post(url, json=data, headers=headers) as response:
            if response.status == 200:
                result = await response.json()
                progress.complete()
                return titulo, result['choices'][0]['message']['content'].strip()
            else:
                progress.complete()
                return titulo, None
    except Exception as e:
        progress.complete()
        return titulo, None

async def aplicar_prompt_a_titulos_concorrentes(indice):
    async with aiohttp.ClientSession() as session:
        total_items = len(indice)
        tasks = [obter_paragrafo(session, item['title'], total_items) for item in indice]
        resultados = await asyncio.gather(*tasks)
        resultados_dict = {titulo: conteudo for titulo, conteudo in resultados}
        return resultados_dict

def processar_indice_concorrente(indice):
    global resultados_completos
    resultados_completos = asyncio.run(aplicar_prompt_a_titulos_concorrentes(indice))

    for titulo, conteudo in resultados_completos.items():
        if conteudo:
            print(f"\n{titulo}\n{'-' * 50}\n{conteudo}\n{'=' * 50}")
        else:
            print(f"\nErro ao gerar conteúdo para: {titulo}\n{'=' * 50}")

    return resultados_completos

if indice_gerado:
    resultados_completos = processar_indice_concorrente(indice_gerado)